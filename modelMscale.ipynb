{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import the required libraries\n",
    "\n",
    "First, let's import the standard ML stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models\n",
    "from torch.nn.parameter import Parameter\n",
    "from thop import profile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have some libraries that are commented out in the source. It's unclear if these are needed so I'm leaving them in for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import apex\n",
    "# import apex.parallel.sync_batchnorm as BN\n",
    "# from .dpn import dpn92"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have some local imports. These aren't standard libraries but instead are locally defined functions. These are defined in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msenet\u001b[39;00m \u001b[39mimport\u001b[39;00m se_resnext50_32x4d, senet154\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mantialias\u001b[39;00m \u001b[39mimport\u001b[39;00m Downsample \u001b[39mas\u001b[39;00m downsamp\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from .senet import se_resnext50_32x4d, senet154\n",
    "from .antialias import Downsample as downsamp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define classes for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ResidualDownSample(nn.Module):\n",
    "    def __init__(self, in_channels, bias=False):\n",
    "        super(ResidualDownSample, self).__init__()\n",
    "        self.bot = nn.Sequential(downsamp(channels=in_channels,filt_size=3,stride=2),\n",
    "                                nn.Conv2d(in_channels, in_channels*2, 1, stride=1, padding=0, bias=bias))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bot(x)\n",
    "        return out\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_channels, scale_factor, stride=2, kernel_size=3):\n",
    "        super(DownSample, self).__init__()\n",
    "        self.scale_factor = int(np.log2(scale_factor))\n",
    "\n",
    "        modules_body = []\n",
    "        for i in range(self.scale_factor):\n",
    "            modules_body.append(ResidualDownSample(in_channels))\n",
    "            in_channels = int(in_channels * stride)\n",
    "\n",
    "        self.body = nn.Sequential(*modules_body)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        return x\n",
    "\n",
    "class ResidualUpSample(nn.Module):\n",
    "    def __init__(self, in_channels, bias=False):\n",
    "        super(ResidualUpSample, self).__init__()\n",
    "\n",
    "        self.bot = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=bias),\n",
    "                                nn.Conv2d(in_channels, in_channels//2, 1, stride=1, padding=0, bias=bias))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bot(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_channels, scale_factor, stride=2, kernel_size=3):\n",
    "        super(UpSample, self).__init__()\n",
    "        self.scale_factor = int(np.log2(scale_factor))\n",
    "\n",
    "        modules_body = []\n",
    "        for i in range(self.scale_factor):\n",
    "            modules_body.append(ResidualUpSample(in_channels))\n",
    "            in_channels = int(in_channels // stride)\n",
    "\n",
    "        self.body = nn.Sequential(*modules_body)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvReluBN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(ConvReluBN, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "class ConvBNReluNkernel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, BN = True):\n",
    "        super(ConvBNReluNkernel, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        if kernel_size == 5:\n",
    "            self.conv= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size = self.kernel_size, padding=2)\n",
    "        if kernel_size == 3:\n",
    "            self.conv= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size = self.kernel_size, padding=1)\n",
    "        if kernel_size == 1:\n",
    "            self.conv= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size = self.kernel_size, padding=0)\n",
    "        if BN == True:\n",
    "            self.BN = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.relu(self.BN(self.conv(x)))\n",
    "        return y\n",
    "\n",
    "\n",
    "class Attention_block(nn.Module):\n",
    "    def __init__(self, F_c, F_de,  reduction=16, concat=True):\n",
    "        super(Attention_block,self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(F_c, F_c//reduction, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 =  nn.Conv2d(F_c//reduction, F_de, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "        self.spatial_se = nn.Sequential(nn.Conv2d(F_de, 1, kernel_size=1,\n",
    "                                                  stride=1, padding=0, bias=False),\n",
    "                                        nn.Sigmoid())\n",
    "        self.concat = concat\n",
    "\n",
    "    def forward(self,f, x):\n",
    "        f=self.avg_pool(f)\n",
    "        f = self.fc1(f)\n",
    "        f = self.relu(f)\n",
    "        f = self.fc2(f)\n",
    "        chn_se = self.sigmoid(f)\n",
    "        chn_se = chn_se * x\n",
    "\n",
    "        spa_se = self.spatial_se(x)\n",
    "        spa_se = x * spa_se\n",
    "\n",
    "        if self.concat:\n",
    "            return torch.cat([chn_se, spa_se], dim=1)\n",
    "        else:\n",
    "            return chn_se + spa_se\n",
    "\n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(ConvRelu, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(inplace=True, )\n",
    "        )\n",
    "    #@autocast()\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class BasicResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, groups=16):\n",
    "        super(BasicResBlock, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n",
    "            nn.GroupNorm(num_groups=4, num_channels=out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # self.conv3 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1)\n",
    "        # self.norm = nn.GroupNorm(num_groups=16, num_channels=out_channels)\n",
    "        # self.relu= nn.ReLU(inplace=True)\n",
    "    #@autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        # x = self.conv3(x)\n",
    "        # x = self.norm(x)\n",
    "        #\n",
    "        # x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class SCSEModule2(nn.Module):\n",
    "    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n",
    "    def __init__(self, channels, reduction=16, concat=False):\n",
    "        super(SCSEModule2, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n",
    "                                                  stride=1, padding=0, bias=False),\n",
    "                                        nn.Sigmoid())\n",
    "        self.concat = concat\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        chn_se = self.sigmoid(x)\n",
    "        chn_se = chn_se * module_input + module_input\n",
    "\n",
    "        spa_se = self.spatial_se(module_input)\n",
    "        #chn_se = chn_se * spa_se\n",
    "        spa_se = module_input * spa_se + module_input\n",
    "        if self.concat:\n",
    "            return torch.cat([chn_se, spa_se], dim=1)\n",
    "        else:\n",
    "            return (chn_se + spa_se)/2\n",
    "\n",
    "\n",
    "class SCSEModule(nn.Module):\n",
    "    # according to https://arxiv.org/pdf/1808.08127.pdf concat is better\n",
    "    def __init__(self, channels, reduction=16, concat=False):\n",
    "        super(SCSEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.spatial_se = nn.Sequential(nn.Conv2d(channels, 1, kernel_size=1,\n",
    "                                                  stride=1, padding=0, bias=False),\n",
    "                                        nn.Sigmoid())\n",
    "        self.concat = concat\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        chn_se = self.sigmoid(x)\n",
    "        chn_se = chn_se * module_input\n",
    "\n",
    "        spa_se = self.spatial_se(module_input)\n",
    "        spa_se = module_input * spa_se\n",
    "        if self.concat:\n",
    "            return torch.cat([chn_se, spa_se], dim=1)\n",
    "        else:\n",
    "            return chn_se + spa_se\n",
    "\n",
    "\n",
    "\n",
    "class SeResNext50_Unet_MScale(nn.Module):\n",
    "    def __init__(self, pretrained='imagenet', **kwargs):\n",
    "        super(SeResNext50_Unet_MScale, self).__init__()\n",
    "\n",
    "        encoder_filters = [64, 256, 512, 1024, 2048]\n",
    "        decoder_filters = [48,  128, 256, 256, 2048]\n",
    "        f_filter = 24\n",
    "\n",
    "        # self.convF2 = ConvRelu(encoder_filters[1]+encoder_filters[1], encoder_filters[1])\n",
    "        # self.convF3 = ConvRelu(encoder_filters[2]+encoder_filters[1], encoder_filters[2])\n",
    "        # self.convF4 = ConvRelu(encoder_filters[3]+encoder_filters[1], encoder_filters[3])\n",
    "\n",
    "        # self.convF1 = nn.Sequential(ConvRelu(f_filter + encoder_filters[0], encoder_filters[0]), BasicResBlock(encoder_filters[0], encoder_filters[0]))\n",
    "        # self.convF2 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[1], encoder_filters[1]), BasicResBlock(encoder_filters[1], encoder_filters[1]))\n",
    "        # self.convF3 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[2], encoder_filters[2]), BasicResBlock(encoder_filters[2], encoder_filters[2]))\n",
    "        self.convF1 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[0], encoder_filters[0]))\n",
    "        self.convF2 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[1], encoder_filters[1]))\n",
    "        #self.convF3 = nn.Sequential(BasicResBlock(f_filter +encoder_filters[2], encoder_filters[2]))\n",
    "        #self.convF4 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[3], encoder_filters[3]), BasicResBlock(encoder_filters[3], encoder_filters[3]))\n",
    "        self.xconv256 =  nn.Sequential(BasicResBlock(3, f_filter))\n",
    "        self.xconv128 =  nn.Sequential(BasicResBlock(3, f_filter))\n",
    "        #self.xconv64 = nn.Sequential(BasicResBlock(3, f_filter))\n",
    "        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n",
    "        self.dconv5 = ConvRelu(encoder_filters[4], decoder_filters[3])\n",
    "        self.dconv5_2 = ConvRelu(encoder_filters[3]+decoder_filters[3], decoder_filters[3])\n",
    "\n",
    "        self.dconv6 = ConvRelu(decoder_filters[3], decoder_filters[2])\n",
    "        self.dconv6_2 = ConvRelu(encoder_filters[2]+decoder_filters[2], decoder_filters[2])\n",
    "        self.dconv7 = ConvRelu(decoder_filters[2], decoder_filters[1])\n",
    "        self.dconv7_2 = ConvRelu(encoder_filters[1]+decoder_filters[1], decoder_filters[1])\n",
    "        self.dconv8 = ConvRelu(decoder_filters[1], decoder_filters[0])\n",
    "        self.dconv8_2 = ConvRelu(encoder_filters[0]+decoder_filters[0], decoder_filters[0])\n",
    "\n",
    "        self.dconv9 = ConvRelu(decoder_filters[0], decoder_filters[0])\n",
    "\n",
    "        self.res = nn.Conv2d(decoder_filters[0]*2, 5, 1, stride=1, padding=0)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        encoder = se_resnext50_32x4d(pretrained=pretrained)\n",
    "        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n",
    "        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n",
    "        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n",
    "        self.conv3 = encoder.layer2\n",
    "        self.conv4 = encoder.layer3\n",
    "        self.conv5 = encoder.layer4\n",
    "\n",
    "        #self.xconv128 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n",
    "        #self.xconv64 = nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n",
    "        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n",
    "\n",
    "    def forward1(self, x):\n",
    "        batch_size, C, H, W = x.shape\n",
    "        x256 = F.interpolate(x, scale_factor=0.5)\n",
    "        x128 = F.interpolate(x, scale_factor=0.25)\n",
    "        #x64 = F.interpolate(x, scale_factor=0.125)\n",
    "        #x32 = F.interpolate(x, scale_factor=0.0625)\n",
    "\n",
    "        enc1 = self.conv1(x)\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "        enc4 = self.conv4(enc3)\n",
    "        enc5 = self.conv5(enc4)\n",
    "\n",
    "        enc256 = self.xconv256(x256)\n",
    "        enc128 = self.xconv128(x128)\n",
    "        #enc64 = self.xconv64(x64)\n",
    "        #enc32 = self.xconv32(x32)\n",
    "\n",
    "        enc1 = self.convF1(torch.cat([enc1, enc256],1))\n",
    "        enc2 = self.convF2(torch.cat([enc2, enc128], 1))\n",
    "        #enc3 = self.convF3(torch.cat([enc3, enc64], 1))\n",
    "        #enc4 = self.convF4(torch.cat([enc4, enc32], 1))\n",
    "\n",
    "\n",
    "        dec5 = self.dconv5(F.interpolate(enc5, scale_factor=2))\n",
    "        dec5 = self.dconv5_2(torch.cat([dec5,enc4], 1))\n",
    "        dec6 = self.dconv6(F.interpolate(dec5, scale_factor=2))\n",
    "        dec6 = self.dconv6_2(torch.cat([dec6,enc3], 1))\n",
    "        dec7 = self.dconv7(F.interpolate(dec6, scale_factor=2))\n",
    "        dec7 = self.dconv7_2(torch.cat([dec7,enc2], 1))\n",
    "        dec8 = self.dconv8(F.interpolate(dec7, scale_factor=2))\n",
    "        dec8 = self.dconv8_2(torch.cat([dec8,enc1], 1))\n",
    "\n",
    "        dec9 = self.dconv9(F.interpolate(dec8,scale_factor=2))\n",
    "\n",
    "        return dec9\n",
    "\n",
    "    def forward(self, x):\n",
    "        dec10_0 = self.forward1(x[:, :3, :, :])\n",
    "        dec10_1 = self.forward1(x[:, 3:, :, :])\n",
    "\n",
    "        dec10 = torch.cat([dec10_0, dec10_1], 1)\n",
    "\n",
    "        return self.res(dec10)\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "class SeResNext50_Unet_MScale2(nn.Module):\n",
    "    def __init__(self, pretrained='imagenet', **kwargs):\n",
    "        super(SeResNext50_Unet_MScale2, self).__init__()\n",
    "\n",
    "        encoder_filters = [64, 256, 512, 1024, 2048]\n",
    "        decoder_filters = [48,  128, 256, 256, 2048]\n",
    "        f_filter = 24\n",
    "\n",
    "        # self.convF2 = ConvRelu(encoder_filters[1]+encoder_filters[1], encoder_filters[1])\n",
    "        # self.convF3 = ConvRelu(encoder_filters[2]+encoder_filters[1], encoder_filters[2])\n",
    "        # self.convF4 = ConvRelu(encoder_filters[3]+encoder_filters[1], encoder_filters[3])\n",
    "\n",
    "        # self.convF1 = nn.Sequential(ConvRelu(f_filter + encoder_filters[0], encoder_filters[0]), BasicResBlock(encoder_filters[0], encoder_filters[0]))\n",
    "        # self.convF2 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[1], encoder_filters[1]), BasicResBlock(encoder_filters[1], encoder_filters[1]))\n",
    "        # self.convF3 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[2], encoder_filters[2]), BasicResBlock(encoder_filters[2], encoder_filters[2]))\n",
    "        #self.convF1 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[0], encoder_filters[0]))\n",
    "        self.convF2 = nn.Sequential( BasicResBlock(f_filter + encoder_filters[1], encoder_filters[1]))\n",
    "        #self.convF3 = nn.Sequential(BasicResBlock(f_filter +encoder_filters[2], encoder_filters[2]))\n",
    "        #self.convF4 = nn.Sequential(ConvRelu(encoder_filters[1]+ encoder_filters[3], encoder_filters[3]), BasicResBlock(encoder_filters[3], encoder_filters[3]))\n",
    "        #self.xconv256 =  nn.Sequential(BasicResBlock(3, f_filter))\n",
    "        self.xconv128 =  nn.Sequential(BasicResBlock(3, f_filter))\n",
    "        #self.xconv64 = nn.Sequential(BasicResBlock(3, f_filter))\n",
    "        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n",
    "        #self.dconv5 = ConvRelu(encoder_filters[4], decoder_filters[3])\n",
    "        #self.dconv5_2 = ConvRelu(encoder_filters[3]+decoder_filters[3], decoder_filters[3])\n",
    "\n",
    "        self.dconv6 = ConvReluBN(encoder_filters[3], decoder_filters[2])\n",
    "        self.dconv6_2 = ConvRelu(encoder_filters[2]+decoder_filters[2], decoder_filters[2])\n",
    "        self.dconv7 = ConvRelu(decoder_filters[2], decoder_filters[1])\n",
    "        self.dconv7_2 = ConvRelu(encoder_filters[1]+decoder_filters[1], decoder_filters[1])\n",
    "        self.dconv8 = ConvRelu(decoder_filters[1], decoder_filters[0])\n",
    "        self.dconv8_2 = ConvRelu(encoder_filters[0]+decoder_filters[0], decoder_filters[0])\n",
    "        self.dconv8_2 = nn.Sequential( ConvRelu(encoder_filters[0]+decoder_filters[0], decoder_filters[0]), SCSEModule(decoder_filters[0], reduction=2, concat=True))\n",
    "\n",
    "        self.dconv9 = ConvRelu(decoder_filters[0]*2, decoder_filters[0])\n",
    "\n",
    "        self.res = nn.Conv2d(decoder_filters[0]*2, 5, 1, stride=1, padding=0)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        encoder = se_resnext50_32x4d(pretrained=pretrained)\n",
    "        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n",
    "        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n",
    "        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n",
    "        self.conv3 = encoder.layer2\n",
    "        self.conv4 = encoder.layer3\n",
    "        #self.conv5 = encoder.layer4\n",
    "\n",
    "        #self.xconv128 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n",
    "        #self.xconv64 = nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n",
    "        #self.xconv32 =  nn.Sequential(ConvReluBN(in_channels=3, out_channels=64), encoder.layer1 )\n",
    "\n",
    "    def forward1(self, x):\n",
    "        batch_size, C, H, W = x.shape\n",
    "        #x256 = F.interpolate(x, scale_factor=0.5)\n",
    "        x128 = F.interpolate(x, scale_factor=0.25)\n",
    "        #x64 = F.interpolate(x, scale_factor=0.125)\n",
    "        #x32 = F.interpolate(x, scale_factor=0.0625)\n",
    "\n",
    "        enc1 = self.conv1(x)\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "        enc4 = self.conv4(enc3)\n",
    "        #enc5 = self.conv5(enc4)\n",
    "\n",
    "        #enc256 = self.xconv256(x256)\n",
    "        enc128 = self.xconv128(x128)\n",
    "        #enc64 = self.xconv64(x64)\n",
    "        #enc32 = self.xconv32(x32)\n",
    "\n",
    "        #enc1 = self.convF1(torch.cat([enc1, enc256],1))\n",
    "        enc2 = self.convF2(torch.cat([enc2, enc128], 1))\n",
    "        #enc3 = self.convF3(torch.cat([enc3, enc64], 1))\n",
    "        #enc4 = self.convF4(torch.cat([enc4, enc32], 1))\n",
    "\n",
    "\n",
    "        #dec5 = self.dconv5(F.interpolate(enc5, scale_factor=2))\n",
    "        #dec5 = self.dconv5_2(torch.cat([dec5,enc4], 1))\n",
    "        dec6 = self.dconv6(F.interpolate(enc4, scale_factor=2))\n",
    "        dec6 = self.dconv6_2(torch.cat([dec6,enc3], 1))\n",
    "        dec7 = self.dconv7(F.interpolate(dec6, scale_factor=2))\n",
    "        dec7 = self.dconv7_2(torch.cat([dec7,enc2], 1))\n",
    "        dec8 = self.dconv8(F.interpolate(dec7, scale_factor=2))\n",
    "        dec8 = self.dconv8_2(torch.cat([dec8,enc1], 1))\n",
    "\n",
    "        dec9 = self.dconv9(F.interpolate(dec8,scale_factor=2))\n",
    "\n",
    "        return dec9\n",
    "\n",
    "    def forward(self, x):\n",
    "        dec10_0 = self.forward1(x[:, :3, :, :])\n",
    "        dec10_1 = self.forward1(x[:, 3:, :, :])\n",
    "\n",
    "        dec10 = torch.cat([dec10_0, dec10_1], 1)\n",
    "\n",
    "        return self.res(dec10)\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "class SeResNext50_Unet_Double(nn.Module):\n",
    "    def __init__(self, pretrained='imagenet', **kwargs):\n",
    "        super(SeResNext50_Unet_Double, self).__init__()\n",
    "\n",
    "        encoder_filters = [64, 256, 512, 1024, 2048]\n",
    "        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n",
    "\n",
    "        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n",
    "        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n",
    "        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n",
    "        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3], decoder_filters[-2])\n",
    "        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n",
    "        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4], decoder_filters[-3])\n",
    "        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n",
    "        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n",
    "        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n",
    "\n",
    "\n",
    "        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        encoder = se_resnext50_32x4d(pretrained=pretrained)\n",
    "        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n",
    "\n",
    "        # conv1_new = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        # _w = encoder.layer0.conv1.state_dict()\n",
    "        # _w['weight'] = torch.cat([0.5 * _w['weight'], 0.5 * _w['weight']], 1)\n",
    "        # conv1_new.load_state_dict(_w)\n",
    "        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n",
    "        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n",
    "        self.conv3 = encoder.layer2\n",
    "        self.conv4 = encoder.layer3\n",
    "        self.conv5 = encoder.layer4\n",
    "\n",
    "\n",
    "    def forward1(self, x):\n",
    "        batch_size, C, H, W = x.shape\n",
    "\n",
    "        enc1 = self.conv1(x)\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "        enc4 = self.conv4(enc3)\n",
    "        enc5 = self.conv5(enc4)\n",
    "\n",
    "        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n",
    "        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n",
    "\n",
    "        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n",
    "        dec7 = self.conv7_2(torch.cat([dec7, enc3 ], 1))\n",
    "\n",
    "        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n",
    "        dec8 = self.conv8_2(torch.cat([dec8, enc2 ], 1))\n",
    "\n",
    "        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n",
    "        dec9 = self.conv9_2(torch.cat([dec9,  enc1  ], 1))\n",
    "\n",
    "        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n",
    "\n",
    "        return dec10\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        dec10_0 = self.forward1(x[:, :3, :, :])\n",
    "        dec10_1 = self.forward1(x[:, 3:, :, :])\n",
    "\n",
    "        dec10 = torch.cat([dec10_0, dec10_1], 1)\n",
    "\n",
    "        return self.res(dec10)\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "class SeResNext50_Unet_MultiScale(nn.Module):\n",
    "    def __init__(self, pretrained='imagenet', **kwargs):\n",
    "        super(SeResNext50_Unet_MultiScale, self).__init__()\n",
    "\n",
    "        #encoder_filters = [64, 256, 512, 1024, 2048]\n",
    "        encoder_filters = [128, 256, 512, 1024, 2048]\n",
    "        fuse_filter = 64\n",
    "\n",
    "        self.down12 = DownSample(encoder_filters[0], 2)\n",
    "        self.down13 = DownSample(encoder_filters[0]*2, 2)\n",
    "        self.down23 = DownSample(encoder_filters[1], 2)\n",
    "        self.up21 = UpSample(encoder_filters[1], 2)\n",
    "        self.up31 = UpSample(encoder_filters[2]//2, 2)\n",
    "        self.up32 = UpSample(encoder_filters[2], 2)\n",
    "\n",
    "        # self.convF1 = ConvBNReluNkernel(encoder_filters[0], decoder_filters[0])\n",
    "        # self.convF2 = ConvBNReluNkernel(encoder_filters[1], decoder_filters[1])\n",
    "        # self.convF3 = ConvBNReluNkernel(encoder_filters[2], decoder_filters[2])\n",
    "        self.conv0 = ConvRelu(encoder_filters[0]//2, encoder_filters[0])\n",
    "        self.convF1 = nn.Sequential(ConvRelu(encoder_filters[0], encoder_filters[0]), SCSEModule(encoder_filters[0], reduction=4, concat=True))\n",
    "        self.conv1_1 = ConvRelu(encoder_filters[0]*2, encoder_filters[0])\n",
    "        self.convF2 = nn.Sequential(ConvRelu(encoder_filters[1], encoder_filters[1]), SCSEModule(encoder_filters[1], reduction=8, concat=True))\n",
    "        self.conv2_1 = ConvRelu(encoder_filters[1]*2, encoder_filters[1])\n",
    "        self.convF3 = nn.Sequential(ConvRelu(encoder_filters[2], encoder_filters[2]), SCSEModule(encoder_filters[2], reduction=16, concat=True))\n",
    "        self.conv3_1 = ConvRelu(encoder_filters[2]*2, encoder_filters[2])\n",
    "\n",
    "        self.conv1_2 = ConvRelu(encoder_filters[0] * 2, fuse_filter)\n",
    "        self.conv2_2 = ConvRelu(encoder_filters[1] * 2, fuse_filter)\n",
    "        self.conv3_2 = ConvRelu(encoder_filters[2] * 2, fuse_filter*2)\n",
    "        self.up31_2 = UpSample(fuse_filter*2, 4)   #32\n",
    "        self.up21_2 = UpSample(fuse_filter, 2)   #32\n",
    "\n",
    "        self.conv4 = ConvRelu(fuse_filter * 2, fuse_filter)  # 32+32+64\n",
    "        self.conv4_2 = nn.Conv2d(fuse_filter, fuse_filter, 1, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.res = nn.Conv2d(fuse_filter*2, 5, 1, stride=1, padding=0)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        encoder = se_resnext50_32x4d(pretrained=pretrained)\n",
    "        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n",
    "        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n",
    "        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n",
    "        self.conv3 = encoder.layer2\n",
    "        #self.conv4 = encoder.layer3\n",
    "\n",
    "\n",
    "    def forward1(self, x):\n",
    "        batch_size, C, H, W = x.shape\n",
    "\n",
    "        enc1 = self.conv1(x)\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "\n",
    "        enc1 = self.conv0(enc1)\n",
    "\n",
    "        f12 = self.down12(enc1)\n",
    "        f13 = self.down13(f12)\n",
    "        f23 = self.down23(enc2)\n",
    "        f21 = self.up21(enc2)\n",
    "        f32 = self.up32(enc3)\n",
    "        f31 = self.up31(f32)\n",
    "\n",
    "        fusion1 = self.convF1(enc1+f21+f31)\n",
    "        fusion1 = self.conv1_1(fusion1)\n",
    "        fusion2 = self.convF2(enc2+f12+f32)\n",
    "        fusion2 = self.conv2_1(fusion2)\n",
    "        fusion3 = self.convF3(enc3+f23+f13)\n",
    "        fusion3 = self.conv3_1(fusion3)\n",
    "\n",
    "        dec1 = self.conv1_2(torch.cat([enc1, fusion1], 1))\n",
    "        dec2 = self.conv2_2(torch.cat([enc2, fusion2], 1))\n",
    "        dec3 = self.conv3_2(torch.cat([enc3, fusion3], 1))\n",
    "\n",
    "        dec2 = self.up21_2(dec2)\n",
    "        dec3 = self.up31_2(dec3)\n",
    "        dec4 = self.conv4(torch.cat([dec1, dec2, dec3], 1))\n",
    "        dec4 = self.conv4_2(F.interpolate(dec4, scale_factor=2, mode='bilinear'))\n",
    "        dec4 = self.relu(dec4)\n",
    "\n",
    "        return dec4\n",
    "\n",
    "    def forward(self, x):\n",
    "        dec10_0 = self.forward1(x[:, :3, :, :])\n",
    "        dec10_1 = self.forward1(x[:, 3:, :, :])\n",
    "\n",
    "        dec10 = torch.cat([dec10_0, dec10_1], 1)\n",
    "\n",
    "        return self.res(dec10)\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "class SeResNext50_Unet_2SUnet(nn.Module):\n",
    "    def __init__(self, pretrained='imagenet', **kwargs):\n",
    "        super(SeResNext50_Unet_2SUnet, self).__init__()\n",
    "\n",
    "        encoder_filters = [64, 256, 512, 1024, 2048]\n",
    "        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n",
    "\n",
    "        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n",
    "        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n",
    "        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n",
    "        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3] , decoder_filters[-2] )\n",
    "        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n",
    "        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4] , decoder_filters[-3])\n",
    "        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n",
    "        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n",
    "        # self.conv9_3 = nn.Sequential(ConvRelu(encoder_filters[-4], encoder_filters[-4]), nn.Sigmoid())\n",
    "        # self.convx9_3 = ConvRelu(encoder_filters[-4], encoder_filters[-4])\n",
    "\n",
    "        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n",
    "        self.convxx = nn.Sequential(ConvRelu(decoder_filters[-5]*2, decoder_filters[-5]*2),\n",
    "                                    nn.Conv2d(decoder_filters[-5] * 2, decoder_filters[-5], 1, stride=1, padding=0))\n",
    "\n",
    "\n",
    "        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        encoder = se_resnext50_32x4d(pretrained=pretrained)\n",
    "        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n",
    "        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n",
    "        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n",
    "        self.conv3 = encoder.layer2\n",
    "        self.conv4 = encoder.layer3\n",
    "        self.conv5 = encoder.layer4\n",
    "\n",
    "\n",
    "    def forward1(self, x):\n",
    "        batch_size, C, H, W = x.shape\n",
    "        xx = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "\n",
    "        enc1 = self.conv1(x)\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "        enc4 = self.conv4(enc3)\n",
    "        enc5 = self.conv5(enc4)\n",
    "\n",
    "        encx1 = self.conv1(xx)   # 64 128 128\n",
    "        encx2 = self.conv2(encx1) # 64\n",
    "        encx3 = self.conv3(encx2) # 32\n",
    "        encx4 = self.conv4(encx3) # 16\n",
    "        encx5 = self.conv5(encx4) # 8\n",
    "\n",
    "        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n",
    "        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n",
    "        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n",
    "        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n",
    "        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n",
    "        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n",
    "        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n",
    "        dec9 = self.conv9_2(torch.cat([dec9,  enc1], 1))   #256\n",
    "\n",
    "\n",
    "        decx6 = self.conv6(F.interpolate(encx5, scale_factor=2))\n",
    "        decx6 = self.conv6_2(torch.cat([decx6, encx4 ], 1))\n",
    "        decx7 = self.conv7(F.interpolate(decx6, scale_factor=2))\n",
    "        decx7 = self.conv7_2(torch.cat([decx7, encx3], 1))\n",
    "        decx8 = self.conv8(F.interpolate(decx7, scale_factor=2))\n",
    "        decx8 = self.conv8_2(torch.cat([decx8, encx2], 1))\n",
    "        decx9 = self.conv9(F.interpolate(decx8, scale_factor=2))\n",
    "        decx9 = self.conv9_2(torch.cat([decx9,  encx1], 1))   #128\n",
    "        #decx9 = self.convx9_3(F.interpolate(decx9, scale_factor=4))\n",
    "\n",
    "\n",
    "        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n",
    "        decx10 = self.conv10(F.interpolate(decx9, scale_factor=4))\n",
    "\n",
    "        dec = self.convxx(torch.cat([dec10, decx10], 1))\n",
    "\n",
    "        return dec\n",
    "\n",
    "    def forward(self, x):\n",
    "        dec10_0 = self.forward1(x[:, :3, :, :])\n",
    "        dec10_1 = self.forward1(x[:, 3:, :, :])\n",
    "\n",
    "        dec10 = torch.cat([dec10_0, dec10_1], 1)\n",
    "\n",
    "        return self.res(dec10)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "class SeResNext50_Unet_2Ssum(nn.Module):\n",
    "    def __init__(self, pretrained='imagenet', **kwargs):\n",
    "        super(SeResNext50_Unet_2Ssum, self).__init__()\n",
    "\n",
    "        encoder_filters = [64, 256, 512, 1024, 2048]\n",
    "        decoder_filters = np.asarray([64, 96, 128, 256, 512]) // 2\n",
    "\n",
    "        self.conv6 = ConvRelu(encoder_filters[-1], decoder_filters[-1])\n",
    "        self.conv6_2 = ConvRelu(decoder_filters[-1] + encoder_filters[-2], decoder_filters[-1])\n",
    "        self.conv7 = ConvRelu(decoder_filters[-1], decoder_filters[-2])\n",
    "        self.conv7_2 = ConvRelu(decoder_filters[-2] + encoder_filters[-3] , decoder_filters[-2] )\n",
    "        self.conv8 = ConvRelu(decoder_filters[-2], decoder_filters[-3])\n",
    "        self.conv8_2 = ConvRelu(decoder_filters[-3] + encoder_filters[-4] , decoder_filters[-3])\n",
    "        self.conv9 = ConvRelu(decoder_filters[-3], decoder_filters[-4])\n",
    "        self.conv9_2 = ConvRelu(decoder_filters[-4] + encoder_filters[-5], decoder_filters[-4])\n",
    "\n",
    "        # self.convx9_3 = ConvRelu(encoder_filters[-4], encoder_filters[-4])\n",
    "\n",
    "\n",
    "        self.conv10 = ConvRelu(decoder_filters[-4], decoder_filters[-5])\n",
    "        self.conv10_s = nn.Sequential(ConvRelu(decoder_filters[-5], decoder_filters[-5]),\n",
    "                                      nn.Conv2d(decoder_filters[-5] , 1, 1, stride=1, padding=0),\n",
    "                                      nn.Sigmoid())\n",
    "        # self.convxx = nn.Sequential(ConvRelu(decoder_filters[-5]*2, decoder_filters[-5]*2),\n",
    "        #                             nn.Conv2d(decoder_filters[-5] * 2, decoder_filters[-5], 1, stride=1, padding=0))\n",
    "\n",
    "        self.res = nn.Conv2d(decoder_filters[-5] * 2, 5, 1, stride=1, padding=0)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        encoder = se_resnext50_32x4d(pretrained=pretrained)\n",
    "        #encoder = torchvision.models.resnet50(pretrained=pretrained)\n",
    "        self.conv1 = nn.Sequential(encoder.layer0.conv1, encoder.layer0.bn1, encoder.layer0.relu1) #encoder.layer0.conv1\n",
    "        self.conv2 = nn.Sequential(encoder.pool, encoder.layer1)\n",
    "        self.conv3 = encoder.layer2\n",
    "        self.conv4 = encoder.layer3\n",
    "        self.conv5 = encoder.layer4\n",
    "\n",
    "\n",
    "    def forward1(self, x):\n",
    "        batch_size, C, H, W = x.shape\n",
    "        xx = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "\n",
    "        enc1 = self.conv1(x)\n",
    "        enc2 = self.conv2(enc1)\n",
    "        enc3 = self.conv3(enc2)\n",
    "        enc4 = self.conv4(enc3)\n",
    "        enc5 = self.conv5(enc4)\n",
    "\n",
    "        encx1 = self.conv1(xx)   # 64 128 128\n",
    "        encx2 = self.conv2(encx1) # 64\n",
    "        encx3 = self.conv3(encx2) # 32\n",
    "        encx4 = self.conv4(encx3) # 16\n",
    "        encx5 = self.conv5(encx4) # 8\n",
    "\n",
    "        dec6 = self.conv6(F.interpolate(enc5, scale_factor=2))\n",
    "        dec6 = self.conv6_2(torch.cat([dec6, enc4 ], 1))\n",
    "        dec7 = self.conv7(F.interpolate(dec6, scale_factor=2))\n",
    "        dec7 = self.conv7_2(torch.cat([dec7, enc3], 1))\n",
    "        dec8 = self.conv8(F.interpolate(dec7, scale_factor=2))\n",
    "        dec8 = self.conv8_2(torch.cat([dec8, enc2], 1))\n",
    "        dec9 = self.conv9(F.interpolate(dec8, scale_factor=2))\n",
    "        dec9 = self.conv9_2(torch.cat([dec9,  enc1], 1))   #256\n",
    "\n",
    "        decx6 = self.conv6(F.interpolate(encx5, scale_factor=2))\n",
    "        decx6 = self.conv6_2(torch.cat([decx6, encx4 ], 1))\n",
    "        decx7 = self.conv7(F.interpolate(decx6, scale_factor=2))\n",
    "        decx7 = self.conv7_2(torch.cat([decx7, encx3], 1))\n",
    "        decx8 = self.conv8(F.interpolate(decx7, scale_factor=2))\n",
    "        decx8 = self.conv8_2(torch.cat([decx8, encx2], 1))\n",
    "        decx9 = self.conv9(F.interpolate(decx8, scale_factor=2))\n",
    "        decx9 = self.conv9_2(torch.cat([decx9,  encx1], 1))   #128\n",
    "        #decx9 = self.convx9_3(F.interpolate(decx9, scale_factor=4))\n",
    "\n",
    "\n",
    "        dec10 = self.conv10(F.interpolate(dec9, scale_factor=2))\n",
    "        alpha = self.conv10_s(dec10)\n",
    "        decx10 = self.conv10(F.interpolate(decx9, scale_factor=4))\n",
    "\n",
    "        dec = alpha * dec10 + (1-alpha)*decx10\n",
    "\n",
    "        return dec\n",
    "\n",
    "    def forward(self, x):\n",
    "        dec10_0 = self.forward1(x[:, :3, :, :])\n",
    "        dec10_1 = self.forward1(x[:, 3:, :, :])\n",
    "\n",
    "        dec10 = torch.cat([dec10_0, dec10_1], 1)\n",
    "\n",
    "        return self.res(dec10)\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n",
    "                m.weight.data = nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    #os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1'\n",
    "    size_input = 512 #817 #577 #473 #713\n",
    "    input = torch.rand(1, 6, size_input, size_input)#.cuda()\n",
    "    model = SeResNext50_Unet_MultiScale()#.cuda()\n",
    "    #macs, params = profile(model, inputs=(input, ))\n",
    "    #print(macs, params)\n",
    "    model.eval()\n",
    "    print(model)\n",
    "    output = model(input)\n",
    "    print('PyConvSegNet', output.size())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
